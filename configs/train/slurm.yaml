# @package _group_
distributed_backend: null
batch_size: 32
num_epochs: 200
gpus: 1
gradient_clip_val: 0.5
slurm:
  time: '4:00:00'
  cpus_per_task: 8
  gpus_per_node: ${train.gpus}
  nodes: 1
  account: m1759
